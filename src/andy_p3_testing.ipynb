{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run full notebook as-is for initial model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pymongo\n",
    "from flask import Flask, render_template, jsonify\n",
    "from bson.json_util import dumps\n",
    "from config import USER, PASSWORD\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = f'mongodb+srv://{USER}:{PASSWORD}@weatherviz-andy-5dubo.mongodb.net/gtds_p3?retryWrites=true'\n",
    "client = pymongo.MongoClient(conn)\n",
    "db = client.gtds_p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# household_total = 0\n",
    "# for i in range(1993,2018):\n",
    "#     url = f' https://api.bjs.ojp.gov/bjs/ncvs/v2/household/{i}?format=json'\n",
    "#     res = requests.get(url).json()\n",
    "#     data = res['householdData']\n",
    "#     household_total += len(res['householdData'])\n",
    "#     print(f\"year: {i}, records: {len(res['householdData'])}\")\n",
    "#     db.household.insert_many(data)\n",
    "    \n",
    "# print(f'total records: {household_total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "records = db.population.find()\n",
    "df = pd.DataFrame(list(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                43200\n",
       "hh_income          43200\n",
       "injury             43200\n",
       "incident_loc       43200\n",
       "residence_loc      43200\n",
       "marital_status     43200\n",
       "pop_size           43200\n",
       "race               43200\n",
       "region             43200\n",
       "police_report      43200\n",
       "sex                43200\n",
       "type_crime         43200\n",
       "vo_relationship    43200\n",
       "tw                 43200\n",
       "year               43200\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trimmed = df.iloc[:, [0,3,4,5,6,7,9,11,13,14,16,17,19,20,44]]\n",
    "\n",
    "df_renamed = df_trimmed.rename(columns={\n",
    "    'Age': 'age',\n",
    "    'Household income': 'hh_income',\n",
    "    'Location of incident':'incident_loc',\n",
    "    'Injury':'injury',\n",
    "    'Location of residence':'residence_loc',\n",
    "    'Marital status':'marital_status',\n",
    "    'Population size':'pop_size',\n",
    "    'Race':'race',\n",
    "    'Region':'region',\n",
    "    'Reporting to the police':'police_report',\n",
    "    'Sex':'sex',\n",
    "    'Type of crime':'type_crime',\n",
    "    'Victim-offender relationship':'vo_relationship',\n",
    "    'Weapon category':'tw'\n",
    "})\n",
    "df_renamed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from keras.utils import to_categorical\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_renamed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_renamed.drop(columns=['sex'], axis=1)\n",
    "# y = df_renamed['sex']\n",
    "# print(X.shape, y.shape)\n",
    "\n",
    "df_sm = df_renamed[['sex','age','type_crime','vo_relationship']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43200, 3) (43200,)\n"
     ]
    }
   ],
   "source": [
    "X = df_sm.drop(columns=['type_crime'], axis=1)\n",
    "y = df_sm['type_crime']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_categorical = pd.get_dummies(X)\n",
    "# X_categorical = X_categorical.drop(columns=['year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age_12_to_14', 'age_15_to_17', 'age_18_to_20', 'age_21_to_24',\n",
       "       'age_25_to_34', 'age_35_to_49', 'age_50_to_64', 'age_65_or_older',\n",
       "       'type_crime_aggravated_assault', 'type_crime_personal_theft',\n",
       "       'type_crime_rape/sexual_assault', 'type_crime_robbery',\n",
       "       'type_crime_simple_assault',\n",
       "       'vo_relationship_do_not_know_number_of_offenders',\n",
       "       'vo_relationship_do_not_know_relationship', 'vo_relationship_intimates',\n",
       "       'vo_relationship_other_relatives', 'vo_relationship_stranger',\n",
       "       'vo_relationship_well-known/casual_acquaintances'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cols = []\n",
    "for x in X_categorical.columns:\n",
    "    x = x.lower().split(' ')\n",
    "    x = '_'.join(x)\n",
    "   \n",
    "    if(',' in x):\n",
    "        x = x.split(',')\n",
    "        x = ''.join(x)\n",
    "        \n",
    "    if('$' in x):\n",
    "        x = x.split('$')\n",
    "        x = ''.join(x)\n",
    "\n",
    "    if(\"'\" in x):\n",
    "        x = x.split(\"'\")\n",
    "        x = ''.join(x)\n",
    "        \n",
    "    new_cols.append(x)\n",
    "    \n",
    "X_categorical.columns = new_cols\n",
    "feature_names = X_categorical.columns\n",
    "X_categorical.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_categorical, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6444444444444445"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6451851851851852"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sorted(zip(rf.feature_importances_, feature_names), reverse=True)\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.328436</td>\n",
       "      <td>vo_relationship_intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.167652</td>\n",
       "      <td>vo_relationship_stranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.158599</td>\n",
       "      <td>type_crime_rape/sexual_assault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.045264</td>\n",
       "      <td>vo_relationship_well-known/casual_acquaintances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.044587</td>\n",
       "      <td>vo_relationship_other_relatives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.030426</td>\n",
       "      <td>type_crime_personal_theft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.027947</td>\n",
       "      <td>age_12_to_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.027527</td>\n",
       "      <td>type_crime_aggravated_assault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.027108</td>\n",
       "      <td>type_crime_simple_assault</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.021713</td>\n",
       "      <td>vo_relationship_do_not_know_relationship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.018948</td>\n",
       "      <td>type_crime_robbery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.018087</td>\n",
       "      <td>age_15_to_17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.014432</td>\n",
       "      <td>age_18_to_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.014033</td>\n",
       "      <td>age_50_to_64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.012972</td>\n",
       "      <td>vo_relationship_do_not_know_number_of_offenders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.012498</td>\n",
       "      <td>age_35_to_49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.010987</td>\n",
       "      <td>age_65_or_older</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.010694</td>\n",
       "      <td>age_25_to_34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.008090</td>\n",
       "      <td>age_21_to_24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                                                1\n",
       "0   0.328436                        vo_relationship_intimates\n",
       "1   0.167652                         vo_relationship_stranger\n",
       "2   0.158599                   type_crime_rape/sexual_assault\n",
       "3   0.045264  vo_relationship_well-known/casual_acquaintances\n",
       "4   0.044587                  vo_relationship_other_relatives\n",
       "5   0.030426                        type_crime_personal_theft\n",
       "6   0.027947                                     age_12_to_14\n",
       "7   0.027527                    type_crime_aggravated_assault\n",
       "8   0.027108                        type_crime_simple_assault\n",
       "9   0.021713         vo_relationship_do_not_know_relationship\n",
       "10  0.018948                               type_crime_robbery\n",
       "11  0.018087                                     age_15_to_17\n",
       "12  0.014432                                     age_18_to_20\n",
       "13  0.014033                                     age_50_to_64\n",
       "14  0.012972  vo_relationship_do_not_know_number_of_offenders\n",
       "15  0.012498                                     age_35_to_49\n",
       "16  0.010987                                  age_65_or_older\n",
       "17  0.010694                                     age_25_to_34\n",
       "18  0.008090                                     age_21_to_24"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=100, activation='relu', input_dim=64))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 3s - loss: 0.6113 - acc: 0.6683\n",
      "Epoch 2/100\n",
      " - 3s - loss: 0.5933 - acc: 0.6848\n",
      "Epoch 3/100\n",
      " - 3s - loss: 0.5840 - acc: 0.6935\n",
      "Epoch 4/100\n",
      " - 3s - loss: 0.5735 - acc: 0.7009\n",
      "Epoch 5/100\n",
      " - 3s - loss: 0.5634 - acc: 0.7106\n",
      "Epoch 6/100\n",
      " - 3s - loss: 0.5527 - acc: 0.7178\n",
      "Epoch 7/100\n",
      " - 3s - loss: 0.5403 - acc: 0.7273\n",
      "Epoch 8/100\n",
      " - 3s - loss: 0.5279 - acc: 0.7369\n",
      "Epoch 9/100\n",
      " - 3s - loss: 0.5106 - acc: 0.7468\n",
      "Epoch 10/100\n",
      " - 3s - loss: 0.4973 - acc: 0.7574\n",
      "Epoch 11/100\n",
      " - 3s - loss: 0.4813 - acc: 0.7650\n",
      "Epoch 12/100\n",
      " - 3s - loss: 0.4651 - acc: 0.7760\n",
      "Epoch 13/100\n",
      " - 3s - loss: 0.4490 - acc: 0.7863\n",
      "Epoch 14/100\n",
      " - 3s - loss: 0.4338 - acc: 0.7960\n",
      "Epoch 15/100\n",
      " - 3s - loss: 0.4190 - acc: 0.8000\n",
      "Epoch 16/100\n",
      " - 3s - loss: 0.4049 - acc: 0.8080\n",
      "Epoch 17/100\n",
      " - 3s - loss: 0.3867 - acc: 0.8175\n",
      "Epoch 18/100\n",
      " - 3s - loss: 0.3758 - acc: 0.8225\n",
      "Epoch 19/100\n",
      " - 3s - loss: 0.3601 - acc: 0.8312\n",
      "Epoch 20/100\n",
      " - 3s - loss: 0.3500 - acc: 0.8366\n",
      "Epoch 21/100\n",
      " - 3s - loss: 0.3358 - acc: 0.8429\n",
      "Epoch 22/100\n",
      " - 3s - loss: 0.3282 - acc: 0.8472\n",
      "Epoch 23/100\n",
      " - 3s - loss: 0.3153 - acc: 0.8540\n",
      "Epoch 24/100\n",
      " - 3s - loss: 0.3039 - acc: 0.8593\n",
      "Epoch 25/100\n",
      " - 3s - loss: 0.2977 - acc: 0.8629\n",
      "Epoch 26/100\n",
      " - 3s - loss: 0.2918 - acc: 0.8667\n",
      "Epoch 27/100\n",
      " - 3s - loss: 0.2771 - acc: 0.8729\n",
      "Epoch 28/100\n",
      " - 3s - loss: 0.2721 - acc: 0.8752\n",
      "Epoch 29/100\n",
      " - 3s - loss: 0.2638 - acc: 0.8794\n",
      "Epoch 30/100\n",
      " - 3s - loss: 0.2564 - acc: 0.8859\n",
      "Epoch 31/100\n",
      " - 3s - loss: 0.2500 - acc: 0.8872\n",
      "Epoch 32/100\n",
      " - 3s - loss: 0.2479 - acc: 0.8906\n",
      "Epoch 33/100\n",
      " - 3s - loss: 0.2377 - acc: 0.8938\n",
      "Epoch 34/100\n",
      " - 3s - loss: 0.2370 - acc: 0.8939\n",
      "Epoch 35/100\n",
      " - 3s - loss: 0.2313 - acc: 0.8965\n",
      "Epoch 36/100\n",
      " - 3s - loss: 0.2219 - acc: 0.9014\n",
      "Epoch 37/100\n",
      " - 3s - loss: 0.2185 - acc: 0.9019\n",
      "Epoch 38/100\n",
      " - 3s - loss: 0.2139 - acc: 0.9060\n",
      "Epoch 39/100\n",
      " - 3s - loss: 0.2109 - acc: 0.9066\n",
      "Epoch 40/100\n",
      " - 3s - loss: 0.2089 - acc: 0.9084\n",
      "Epoch 41/100\n",
      " - 3s - loss: 0.2037 - acc: 0.9095\n",
      "Epoch 42/100\n",
      " - 3s - loss: 0.2001 - acc: 0.9128\n",
      "Epoch 43/100\n",
      " - 3s - loss: 0.1916 - acc: 0.9152\n",
      "Epoch 44/100\n",
      " - 3s - loss: 0.1892 - acc: 0.9160\n",
      "Epoch 45/100\n",
      " - 3s - loss: 0.1912 - acc: 0.9167\n",
      "Epoch 46/100\n",
      " - 3s - loss: 0.1846 - acc: 0.9171\n",
      "Epoch 47/100\n",
      " - 3s - loss: 0.1840 - acc: 0.9185\n",
      "Epoch 48/100\n",
      " - 3s - loss: 0.1852 - acc: 0.9185\n",
      "Epoch 49/100\n",
      " - 3s - loss: 0.1747 - acc: 0.9231\n",
      "Epoch 50/100\n",
      " - 3s - loss: 0.1749 - acc: 0.9234\n",
      "Epoch 51/100\n",
      " - 3s - loss: 0.1744 - acc: 0.9240\n",
      "Epoch 52/100\n",
      " - 3s - loss: 0.1684 - acc: 0.9272\n",
      "Epoch 53/100\n",
      " - 3s - loss: 0.1715 - acc: 0.9260\n",
      "Epoch 54/100\n",
      " - 3s - loss: 0.1680 - acc: 0.9271\n",
      "Epoch 55/100\n",
      " - 3s - loss: 0.1637 - acc: 0.9285\n",
      "Epoch 56/100\n",
      " - 3s - loss: 0.1614 - acc: 0.9298\n",
      "Epoch 57/100\n",
      " - 3s - loss: 0.1598 - acc: 0.9301\n",
      "Epoch 58/100\n",
      " - 3s - loss: 0.1624 - acc: 0.9295\n",
      "Epoch 59/100\n",
      " - 3s - loss: 0.1592 - acc: 0.9307\n",
      "Epoch 60/100\n",
      " - 3s - loss: 0.1537 - acc: 0.9329\n",
      "Epoch 61/100\n",
      " - 3s - loss: 0.1514 - acc: 0.9331\n",
      "Epoch 62/100\n",
      " - 3s - loss: 0.1536 - acc: 0.9312\n",
      "Epoch 63/100\n",
      " - 3s - loss: 0.1503 - acc: 0.9333\n",
      "Epoch 64/100\n",
      " - 3s - loss: 0.1504 - acc: 0.9335\n",
      "Epoch 65/100\n",
      " - 3s - loss: 0.1443 - acc: 0.9360\n",
      "Epoch 66/100\n",
      " - 3s - loss: 0.1498 - acc: 0.9361\n",
      "Epoch 67/100\n",
      " - 3s - loss: 0.1470 - acc: 0.9350\n",
      "Epoch 68/100\n",
      " - 3s - loss: 0.1414 - acc: 0.9390\n",
      "Epoch 69/100\n",
      " - 3s - loss: 0.1413 - acc: 0.9377\n",
      "Epoch 70/100\n",
      " - 3s - loss: 0.1411 - acc: 0.9384\n",
      "Epoch 71/100\n",
      " - 3s - loss: 0.1435 - acc: 0.9378\n",
      "Epoch 72/100\n",
      " - 3s - loss: 0.1400 - acc: 0.9396\n",
      "Epoch 73/100\n",
      " - 3s - loss: 0.1384 - acc: 0.9416\n",
      "Epoch 74/100\n",
      " - 3s - loss: 0.1480 - acc: 0.9371\n",
      "Epoch 75/100\n",
      " - 3s - loss: 0.1404 - acc: 0.9373\n",
      "Epoch 76/100\n",
      " - 3s - loss: 0.1342 - acc: 0.9414\n",
      "Epoch 77/100\n",
      " - 3s - loss: 0.1339 - acc: 0.9420\n",
      "Epoch 78/100\n",
      " - 3s - loss: 0.1353 - acc: 0.9410\n",
      "Epoch 79/100\n",
      " - 3s - loss: 0.1352 - acc: 0.9410\n",
      "Epoch 80/100\n",
      " - 3s - loss: 0.1316 - acc: 0.9443\n",
      "Epoch 81/100\n",
      " - 3s - loss: 0.1340 - acc: 0.9416\n",
      "Epoch 82/100\n",
      " - 3s - loss: 0.1337 - acc: 0.9404\n",
      "Epoch 83/100\n",
      " - 3s - loss: 0.1296 - acc: 0.9428\n",
      "Epoch 84/100\n",
      " - 3s - loss: 0.1269 - acc: 0.9433\n",
      "Epoch 85/100\n",
      " - 3s - loss: 0.1293 - acc: 0.9438\n",
      "Epoch 86/100\n",
      " - 3s - loss: 0.1250 - acc: 0.9438\n",
      "Epoch 87/100\n",
      " - 3s - loss: 0.1233 - acc: 0.9444\n",
      "Epoch 88/100\n",
      " - 3s - loss: 0.1256 - acc: 0.9438\n",
      "Epoch 89/100\n",
      " - 3s - loss: 0.1239 - acc: 0.9459\n",
      "Epoch 90/100\n",
      " - 3s - loss: 0.1204 - acc: 0.9456\n",
      "Epoch 91/100\n",
      " - 3s - loss: 0.1194 - acc: 0.9472\n",
      "Epoch 92/100\n",
      " - 3s - loss: 0.1213 - acc: 0.9453\n",
      "Epoch 93/100\n",
      " - 3s - loss: 0.1174 - acc: 0.9465\n",
      "Epoch 94/100\n",
      " - 3s - loss: 0.1180 - acc: 0.9466\n",
      "Epoch 95/100\n",
      " - 3s - loss: 0.1210 - acc: 0.9456\n",
      "Epoch 96/100\n",
      " - 3s - loss: 0.1157 - acc: 0.9480\n",
      "Epoch 97/100\n",
      " - 3s - loss: 0.1245 - acc: 0.9452\n",
      "Epoch 98/100\n"
     ]
    }
   ],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_predictions = model.predict_classes(X_test_scaled[:100])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(f\"Predicted classes: {prediction_labels}\")\n",
    "# print(f\"Actual Labels: {list(y_test[:100])}\")\n",
    "pd.DataFrame({'predicted':prediction_labels, 'actual':list(y_test[:100])})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
